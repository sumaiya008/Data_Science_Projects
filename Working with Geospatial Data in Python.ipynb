{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b739d1fb",
   "metadata": {},
   "source": [
    "https://campus.datacamp.com/courses/working-with-geospatial-data-in-python/introduction-to-geospatial-vector-data?ex=1\n",
    "\n",
    "#### Restaurants in Paris\n",
    "Throughout the exercises in this course, we will work with several datasets about the city of Paris.\n",
    "\n",
    "In this exercise, we will start with exploring a dataset about the restaurants in the center of Paris (compiled from a Paris Data open dataset). The data contains the coordinates of the point locations of the restaurants and a description of the type of restaurant.\n",
    "\n",
    "We expect that you are familiar with the basics of the pandas library to work with tabular data (DataFrame objects) in Python. Here, we will use pandas to read the provided csv file, and then use matplotlib to make a visualization of the points. With matplotlib, we first create a figure and axes object with fig, ax = plt.subplots(), and then use this axes object ax to create the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the restaurants csv file\n",
    "restaurants = pd.read_csv(\"paris_restaurants.csv\")\n",
    "# Inspect the first rows of restaurants\n",
    "print(restaurants.head())\n",
    "\n",
    "# Make a plot of all points\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(restaurants.x, restaurants.y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81bd615",
   "metadata": {},
   "source": [
    "#### Adding a background map\n",
    "A plot with just some points can be hard to interpret without any spatial context. Therefore, in this exercise we will learn how to add a background map.\n",
    "\n",
    "We are going to make use of the contextily package. The add_basemap() function of this package makes it easy to add a background web map to our plot. We begin by plotting our data first, and then pass the matplotlib axes object to the add_basemap() function. contextily will then download the web tiles needed for the geographical extent of your plot.\n",
    "\n",
    "To set the size of the plotted points, we can use the markersize keyword of the plot() method.\n",
    "\n",
    "Pandas has been imported as pd and matplotlib's pyplot functionality as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd060be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the restaurants csv file\n",
    "restaurants = pd.read_csv(\"paris_restaurants.csv\")\n",
    " \n",
    "# Import contextily\n",
    "import contextily\n",
    " \n",
    "# A figure of all restaurants with background\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(restaurants.x, restaurants.y, 'o', markersize=1)\n",
    "contextily.add_basemap(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e778af",
   "metadata": {},
   "source": [
    "### Explore the Paris districts (I)\n",
    "In this exercise, we introduce a next dataset about Paris: the administrative districts of Paris (compiled from a Paris Data open dataset).\n",
    "\n",
    "The dataset is available as a GeoPackage file, a specialised format to store geospatial vector data, and such a file can be read by GeoPandas using the geopandas.read_file() function.\n",
    "\n",
    "To get a first idea of the dataset, we can inspect the first rows with head() and do a quick visualization with `plot(). The attribute information about the districts included in the dataset is the district name and the population (total number of inhabitants of each district)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GeoPandas\n",
    "import geopandas\n",
    " \n",
    "# Read the Paris districts dataset\n",
    "districts = geopandas.read_file('paris_districts.gpkg')\n",
    " \n",
    "# Inspect the first rows\n",
    "print(districts.head())\n",
    " \n",
    "# Make a quick visualization of the districts\n",
    "districts.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195e921",
   "metadata": {},
   "source": [
    "#### Explore the Paris districts (II)\n",
    "In the previous exercise, we used the customized plot() method of the GeoDataFrame, which produces a simple visualization of the geometries in the dataset. The GeoDataFrame and GeoSeries objects can be seen as \"spatial-aware\" DataFrame and Series objects, and compared to their pandas counterparts, they expose additional spatial-specific methods and attributes.\n",
    "\n",
    "The .geometry attribute of a GeoDataFrame always returns the column with the geometry objects as a GeoSeries, whichever the actual name of the column (in the default case it will also be called 'geometry').\n",
    "\n",
    "Another example of extra spatial functionality is the area attribute, giving the area of the polygons.\n",
    "\n",
    "GeoPandas has been imported as geopandas and the districts dataset is available as the districts variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87231e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what kind of object districts is\n",
    "print(type(districts))\n",
    " \n",
    "# Check the type of the geometry attribute\n",
    "print(type(districts.geometry))\n",
    " \n",
    "# Inspect the first rows of the geometry\n",
    "print(districts.geometry.head())\n",
    " \n",
    "# Inspect the area of the districts\n",
    "print(districts.geometry.area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560039f1",
   "metadata": {},
   "source": [
    "#### The Paris restaurants as a GeoDataFrame\n",
    "In the first coding exercise of this chapter, we imported the locations of the restaurants in Paris from a csv file. To enable the geospatial functionality of GeoPandas, we want to convert the pandas DataFrame to a GeoDataFrame. This can be done with the GeoDataFrame() constructor and the geopandas.points_from_xy() function, and is done for you.\n",
    "\n",
    "Now we have a GeoDataFrame, all spatial functionality becomes available, such as plotting the geometries. In this exercise we will make the same figure as in the first exercise with the restaurants dataset, but now using the GeoDataFrame's plot() method.\n",
    "\n",
    "Pandas has been imported as pd, GeoPandas as geopandas and matplotlib's pyplot functionality as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19360727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the restaurants csv file into a DataFrame\n",
    "df = pd.read_csv(\"paris_restaurants.csv\")\n",
    " \n",
    "# Convert it to a GeoDataFrame\n",
    "restaurants = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.x, df.y))\n",
    " \n",
    "# Inspect the first rows of the restaurants GeoDataFrame\n",
    "print(restaurants.head())\n",
    " \n",
    "# Make a plot of the restaurants\n",
    "ax = restaurants.plot(markersize=1)\n",
    "import contextily\n",
    "contextily.add_basemap(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d074381",
   "metadata": {},
   "source": [
    "#### Visualizing the population density\n",
    "Let's get back to the districts dataset. In a previous exercise we visualized the districts with a uniform column. But often we want to show the spatial variation of a variable, and color the polygons accordingly.\n",
    "\n",
    "In this exercise we will visualize the spatial variation of the population density within the center of Paris. For this, we will first calculate the population density by dividing the population number with the area, and add it as a new column to the dataframe.\n",
    "\n",
    "The districts dataset is already loaded as districts, GeoPandas has been imported as geopandas and matplotlib.pyplot as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362de053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first rows of the districts dataset\n",
    "print(districts.head())\n",
    " \n",
    "# Inspect the area of the districts\n",
    "print(districts.area)\n",
    " \n",
    "# Add a population density column\n",
    "districts['population_density'] = districts.population / districts.area * 10**6\n",
    " \n",
    "# Make a plot of the districts colored by the population density\n",
    "districts.plot(column='population_density', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff8aa1",
   "metadata": {},
   "source": [
    "#### Using pandas functionality: groupby\n",
    "This course will focus on the spatial functionality of GeoPandas, but don't forget that we still have a dataframe, and all functionality you know from Pandas is still applicable.\n",
    "\n",
    "In this exercise, we will recap a common functionality: the groupby operation. You may want to use this operation when you have a column containing groups, and you want to calculate a statistic for each group. In the groupby() method, you pass the column that contains the groups. On the resulting object, you can then call the method you want to calculate for each group. In this exercise, we want to know the size of each group of type of restaurants.\n",
    "\n",
    "We refer to the course on Manipulating DataFrames with pandas for more information and exercises on this groupby operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2926f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the restaurants data\n",
    "restaurants = geopandas.read_file(\"paris_restaurants.geosjon\")\n",
    " \n",
    "# Calculate the number of restaurants of each type\n",
    "type_counts = restaurants.groupby('type').size()\n",
    " \n",
    "# Print the result\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2aa45",
   "metadata": {},
   "source": [
    "#### Plotting multiple layers\n",
    "Another typical pandas functionality is filtering a dataframe: taking a subset of the rows based on a condition (which generates a boolean mask).\n",
    "\n",
    "In this exercise, we will take the subset of all African restaurants, and then make a multi-layered plot. In such a plot, we combine the visualization of several GeoDataFrames on a single figure. To add one layer, we can use the ax keyword of the plot() method of a GeoDataFrame to pass it a matplotlib axes object.\n",
    "\n",
    "The restaurants data is already loaded as the restaurants GeoDataFrame. GeoPandas is imported as geopandas and matplotlib.pyplot as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866374d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the restaurants dataset\n",
    "restaurants = geopandas.read_file(\"paris_restaurants.geosjon\")\n",
    " \n",
    "# Take a subset of the African restaurants\n",
    "african_restaurants = restaurants[restaurants['type']=='African restaurant']\n",
    " \n",
    "# Make a multi-layered plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "restaurants.plot(ax=ax, color='grey')\n",
    "african_restaurants.plot(ax=ax, color='red')\n",
    "# Remove the box, ticks and labels\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92775a20",
   "metadata": {},
   "source": [
    "#### Creating a Point geometry\n",
    "The Eiffel Tower is an iron lattice tower built in the 19th century, and is probably the most iconic view of Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41360f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Point geometry\n",
    "from shapely.geometry import Point\n",
    " \n",
    "# Construct a point object for the Eiffel Tower\n",
    "eiffel_tower = Point(255422.6, 6250868.9)\n",
    " \n",
    "# Print the result\n",
    "print(eiffel_tower)\n",
    "# POINT (255422.6 6250868.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505ba28",
   "metadata": {},
   "source": [
    "#### Shapely's spatial methods\n",
    "Now we have a shapely Point object for the Eiffel Tower, we can use the different methods available on such a geometry object to perform spatial operations, such as calculating a distance or checking a spatial relationship.\n",
    "\n",
    "We repeated the construction of eiffel_tower, and also provide the code that extracts one of the neighbourhoods (the Montparnasse district), as well as one of the restaurants located within Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4222039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a point object for the Eiffel Tower\n",
    "eiffel_tower = Point(255422.6, 6250868.9)\n",
    " \n",
    "# Accessing the Montparnasse geometry (Polygon) and restaurant\n",
    "district_montparnasse = districts.loc[52, 'geometry']\n",
    "resto = restaurants.loc[956, 'geometry']\n",
    " \n",
    "# Is the Eiffel Tower located within the Montparnasse district?\n",
    "print(eiffel_tower.within(district_montparnasse))\n",
    "# False\n",
    " \n",
    "# Does the Montparnasse district contains the restaurant?\n",
    "print(district_montparnasse.contains(resto))\n",
    "# True\n",
    " \n",
    "# The distance between the Eiffel Tower and the restaurant?\n",
    "print(eiffel_tower.distance(resto))\n",
    "# 4431.459825587039"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2347571",
   "metadata": {},
   "source": [
    "#### In which district in the Eiffel Tower located?\n",
    "Let's return to the Eiffel Tower example. In previous exercises, we constructed a Point geometry for its location, and we checked that it was not located in the Montparnasse district. Let's now determine in which of the districts of Paris it is located.\n",
    "\n",
    "The districts GeoDataFrame has been loaded, and the Shapely and GeoPandas libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a point object for the Eiffel Tower\n",
    "eiffel_tower = Point(255422.6, 6250868.9)\n",
    " \n",
    "# Create a boolean Series\n",
    "mask = districts.contains(eiffel_tower)\n",
    " \n",
    "# Print the boolean Series\n",
    "print(mask.head())\n",
    " \n",
    "# Filter the districts with the boolean mask\n",
    "print(districts[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575c617",
   "metadata": {},
   "source": [
    "##### How far is the closest restaurant?\n",
    "Now, we might be interested in the restaurants nearby the Eiffel Tower. To explore them, let's visualize the Eiffel Tower itself as well as the restaurants within 1km.\n",
    "\n",
    "To do this, we can calculate the distance to the Eiffel Tower for each of the restaurants. Based on this result, we can then create a mask that takes True if the restaurant is within 1km, and False otherwise, and use it to filter the restaurants GeoDataFrame. Finally, we make a visualization of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9875408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distance from each restaurant to the Eiffel Tower\n",
    "dist_eiffel = restaurants.distance(eiffel_tower)\n",
    " \n",
    "# The distance to the closest restaurant\n",
    "print(dist_eiffel.min())\n",
    "# 460.6976028277898\n",
    " \n",
    "# Filter the restaurants for closer than 1 km\n",
    "restaurants_eiffel = restaurants[dist_eiffel<1000]\n",
    " \n",
    "# Make a plot of the close-by restaurants\n",
    "ax = restaurants_eiffel.plot()\n",
    "geopandas.GeoSeries([eiffel_tower]).plot(ax=ax, color='red')\n",
    "contextily.add_basemap(ax)\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffad67",
   "metadata": {},
   "source": [
    "#### Paris: spatial join of districts and bike stations\n",
    "Let's return to the Paris data on districts and bike stations. We will now use the spatial join operation to identify the district in which each station is located.\n",
    "\n",
    "The districts and bike sharing stations datasets are already pre-loaded for you as the districts and stations GeoDataFrames, and GeoPandas has been imported as geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the districts and stations datasets\n",
    "joined = geopandas.sjoin(stations, districts, op='within')\n",
    " \n",
    "# Inspect the first five rows of the result\n",
    "print(joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b09cb",
   "metadata": {},
   "source": [
    "##### Map of tree density by district (1)\n",
    "Using a dataset of all trees in public spaces in Paris, the goal is to make a map of the tree density by district. For this, we first need to find out how many trees each district contains, which we will do in this exercise. In the following exercise, we will then use this result to calculate the density and create a map.\n",
    "\n",
    "To obtain the tree count by district, we first need to know in which district each tree is located, which we can do with a spatial join. Then, using the result of the spatial join, we will calculate the number of trees located in each district using the pandas 'group-by' functionality.\n",
    "\n",
    "GeoPandas has been imported as geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the trees and districts data\n",
    "trees = geopandas.read_file(\"paris_trees.gpkg\")\n",
    "districts = geopandas.read_file(\"paris_districts_utm.geojson\")\n",
    "\n",
    "# Spatial join of the trees and districts datasets\n",
    "joined = geopandas.sjoin(trees, districts, op='within')\n",
    "\n",
    "# Calculate the number of trees in each district\n",
    "trees_by_district = joined.groupby('district_name').size()\n",
    "\n",
    "# Convert the series to a DataFrame and specify column name\n",
    "trees_by_district = trees_by_district.to_frame(name='n_trees')\n",
    "\n",
    "# Inspect the result\n",
    "print(trees_by_district.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be1db3",
   "metadata": {},
   "source": [
    "##### Map of tree density by district (2)\n",
    "Now we have obtained the number of trees by district, we can make the map of the districts colored by the tree density.\n",
    "\n",
    "For this, we first need to merge the number of trees in each district we calculated in the previous step (trees_by_district) back to the districts dataset. We will use the pd.merge() function to join two dataframes based on a common column.\n",
    "\n",
    "Since not all districts have the same size, it is a fairer comparison to visualize the tree density: the number of trees relative to the area.\n",
    "\n",
    "The district dataset has been pre-loaded as districts, and the final result of the previous exercise (a DataFrame with the number of trees for each district) is available as trees_by_district. GeoPandas has been imported as geopandas and Pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d90713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first rows of the result of the previous exercise\n",
    "print(trees_by_district.head())\n",
    " \n",
    "# Merge the 'districts' and 'trees_by_district' dataframes\n",
    "districts_trees = pd.merge(districts, trees_by_district, on='district_name')\n",
    " \n",
    "# Inspect the result\n",
    "print(districts_trees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'districts' and 'trees_by_district' dataframes\n",
    "districts_trees = pd.merge(districts, trees_by_district, on='district_name')\n",
    "\n",
    "# Add a column with the tree density\n",
    "districts_trees['n_trees_per_area'] = districts_trees['n_trees'] / districts_trees.geometry.area\n",
    "\n",
    "# Make of map of the districts colored by 'n_trees_per_area'\n",
    "districts_trees.plot(column='n_trees_per_area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038bd66",
   "metadata": {},
   "source": [
    "#### Equal interval choropleth\n",
    "In the last exercise, we created a map of the tree density. Now we know more about choropleths, we will explore this visualisation in more detail.\n",
    "\n",
    "First, let's visualize the effect of just using the number of trees versus the number of trees normalized by the area of the district (the tree density). Second, we will create an equal interval version of this map instead of using a continuous color scale. This classification algorithm will split the value space in equal bins and assign a color to each.\n",
    "\n",
    "The district_trees GeoDataFrame, the final result of the previous exercise is already loaded. It includes the variable n_trees_per_area, measuring tree density by district (note the variable has been multiplied by 10,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da427c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first rows of the tree density dataset\n",
    "print(districts_trees.head())\n",
    " \n",
    "# Make a choropleth of the number of trees \n",
    "districts_trees.plot(column='n_trees', legend=True)\n",
    "plt.show()\n",
    " \n",
    "# Make a choropleth of the number of trees per area\n",
    "districts_trees.plot(column='n_trees_per_area', legend=True)\n",
    "plt.show()\n",
    " \n",
    "# Make a choropleth of the number of trees \n",
    "districts_trees.plot(column='n_trees_per_area', scheme='equal_interval', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00cf6a",
   "metadata": {},
   "source": [
    "#### Quantiles choropleth\n",
    "In this exercise we will create a quantile version of the tree density map. Remember that the quantile algorithm will rank and split the values into groups with the same number of elements to assign a color to each. This time, we will create seven groups that allocate the colors of the YlGn colormap across the entire set of values.\n",
    "\n",
    "The district_trees GeoDataFrame is again already loaded. It includes the variable n_trees_per_area, measuring tree density by district (note the variable has been multiplied by 10,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the choropleth and store the axis\n",
    "ax = districts_trees.plot(column='n_trees_per_area', scheme='quantiles',\n",
    "                          k=7, cmap='YlGn', legend=True)\n",
    " \n",
    "# Remove frames, ticks and tick labels from the axis\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60514de",
   "metadata": {},
   "source": [
    "#### Compare classification algorithms\n",
    "In this final exercise, you will build a multi map figure that will allow you to compare the two approaches to map variables we have seen.\n",
    "\n",
    "You will rely on standard matplotlib patterns to build a figure with two subplots (Axes axes[0] and axes[1]) and display in each of them, respectively, an equal interval and quantile based choropleth. Once created, compare them visually to explore the differences that the classification algorithm can have on the final result.\n",
    "\n",
    "This exercise comes with a GeoDataFrame object loaded under the name district_trees that includes the variable n_trees_per_area, measuring tree density by district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and subplots\n",
    "fig, axes = plt.subplots(nrows=2)\n",
    " \n",
    "# Plot equal interval map\n",
    "districts_trees.plot('n_trees_per_area', scheme='equal_interval', k=5, legend=True, ax=axes[0])\n",
    "axes[0].set_title('Equal Interval')\n",
    "axes[0].set_axis_off()\n",
    " \n",
    "# Plot quantiles map\n",
    "districts_trees.plot('n_trees_per_area', scheme='quantiles', k=5, legend=True, ax=axes[1])\n",
    "axes[1].set_title('Quantiles')\n",
    "axes[1].set_axis_off()\n",
    " \n",
    "# Display maps\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd34900",
   "metadata": {},
   "source": [
    "#### Geographic vs projected coordinates\n",
    "The CRS attribute stores the information about the Coordinate Reference System in which the data is represented. In this exercises, we will explore the CRS and the coordinates of the districts dataset about the districts of Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the districts dataset\n",
    "districts = geopandas.read_file(\"paris_districts.geojson\")\n",
    " \n",
    "# Print the CRS information\n",
    "print(districts.crs)\n",
    "# {'init': 'epsg:4326'}\n",
    " \n",
    "# Print the first rows of the GeoDataFrame\n",
    "print(districts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30540d4a",
   "metadata": {},
   "source": [
    "#### Projecting a GeoDataFrame\n",
    "The Paris districts dataset is provided in geographical coordinates (longitude/latitude in WGS84). To see the result of naively using the data as is for plotting or doing calculations, we will first plot the data as is, and then plot a projected version.\n",
    "\n",
    "The standard projected CRS for France is the RGF93 / Lambert-93 reference system (referenced by the EPSG:2154 number).\n",
    "\n",
    "GeoPandas and matplotlib have already been imported, and the districts dataset is read and assigned to the districts variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the CRS information\n",
    "print(districts.crs)\n",
    "# {'init': 'epsg:4326'}\n",
    " \n",
    "# Plot the districts dataset\n",
    "districts.plot()\n",
    "plt.show()\n",
    " \n",
    "# Convert the districts to the RGF93 reference system\n",
    "districts_RGF93 = districts.to_crs(epsg=2154)\n",
    " \n",
    "# Plot the districts dataset again\n",
    "districts_RGF93.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bbc1f",
   "metadata": {},
   "source": [
    "##### Projecting a Point\n",
    "In the previous chapter, we worked with the Eiffel Tower location. Again, we provided you the coordinates in a projected coordinate system, so you could, for example, calculate distances. Let's return to this iconic landmark, and express its location in geographical coordinates: 48°51′29.6″N, 2°17′40.2″E. Or, in decimals: latitude of 48.8584 and longitude of 2.2945.\n",
    "\n",
    "Shapely geometry objects have no notion of a CRS, and thus cannot be directly converted to another CRS. Therefore, we are going to use the GeoPandas to transform the Eiffel Tower point location to an alternative CRS. We will put the single point in a GeoSeries, use the to_crs() method, and extract the point again.\n",
    "\n",
    "GeoPandas is already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b94920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a Point object for the Eiffel Tower\n",
    "from shapely.geometry import Point\n",
    "eiffel_tower = Point(2.2945, 48.8584)\n",
    " \n",
    "# Put the point in a GeoSeries with the correct CRS\n",
    "s_eiffel_tower = geopandas.GeoSeries([eiffel_tower], crs={'init': 'EPSG:4326'})\n",
    " \n",
    "# Convert to other CRS\n",
    "s_eiffel_tower_projected = s_eiffel_tower.to_crs(epsg=2154)\n",
    " \n",
    "# Print the projected point\n",
    "print(s_eiffel_tower_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47353d0d",
   "metadata": {},
   "source": [
    "#### Calculating distance in a projected CRS\n",
    "Now we have the Eiffel Tower location in a projected coordinate system, we can calculate the distance to other points.\n",
    "\n",
    "The final s_eiffel_tower_projected of the previous exercise containing the projected Point is already provided, and we extract the single point into the eiffel_tower variable. Further, the restaurants dataframe (using WGS84 coordinates) is also loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the single Point\n",
    "eiffel_tower = s_eiffel_tower_projected[0]\n",
    " \n",
    "# Ensure the restaurants use the same CRS\n",
    "restaurants = restaurants.to_crs(s_eiffel_tower_projected.crs)\n",
    " \n",
    "# The distance from each restaurant to the Eiffel Tower\n",
    "dist_eiffel = restaurants.distance(eiffel_tower)\n",
    " \n",
    "# The distance to the closest restaurant\n",
    "print(min(dist_eiffel))\n",
    "# 303.56255387894674"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec65271",
   "metadata": {},
   "source": [
    "#### Projecting to Web Mercator for using web tiles\n",
    "In the first chapter, we did an exercise on plotting the restaurant locations in Paris and adding a background map to it using the contextily package.\n",
    "\n",
    "Currently, contextily assumes that your data is in the Web Mercator projection, the system used by most web tile services. And in that first exercise, we provided the data in the appropriate CRS so you didn't need to care about this aspect.\n",
    "\n",
    "However, typically, your data will not come in Web Mercator (EPSG:3857) and you will have to align them with web tiles on your own.\n",
    "\n",
    "GeoPandas, matplotlib and contextily are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to the Web Mercator projection\n",
    "restaurants_webmercator = restaurants.to_crs(epsg=3857)\n",
    " \n",
    "# Plot the restaurants with a background map\n",
    "ax = restaurants_webmercator.plot(markersize=1)\n",
    "contextily.add_basemap(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e1487",
   "metadata": {},
   "source": [
    "#### Exploring a Land Use dataset\n",
    "For the following exercises, we first introduce a new dataset: a dataset about the land use of Paris (a simplified version based on the open European Urban Atlas). The land use indicates for what kind of activity a certain area is used, such as residential area or for recreation. It is a polygon dataset, with a label representing the land use class for different areas in Paris.\n",
    "\n",
    "In this exercise, we will read the data, explore it visually, and calculate the total area of the different classes of land use in the area of Paris.\n",
    "\n",
    "GeoPandas and matplotlib are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the land use dataset\n",
    "land_use = geopandas.read_file('paris_land_use.shp')\n",
    "print(land_use.head())\n",
    " \n",
    "# Make a plot of the land use with 'class' as the color\n",
    "land_use.plot(column='class', legend=True, figsize=(15, 10))\n",
    "plt.show()\n",
    " \n",
    "# Add the area as a new column\n",
    "land_use['area'] = land_use.area\n",
    " \n",
    "# Calculate the total area for each land use class\n",
    "total_area = land_use.groupby('class')['area'].sum() / 1000**2\n",
    "print(total_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad55493",
   "metadata": {},
   "source": [
    "##### Intersection of two polygons\n",
    "For this exercise, we are going to use 2 individual polygons: the district of Muette extracted from the districts dataset, and the green urban area of Boulogne, a large public park in the west of Paris, extracted from the land_use dataset. The two polygons have already been assigned to the muette and park_boulogne variables.\n",
    "\n",
    "We first visualize the two polygons. You will see that they overlap, but the park is not fully located in the district of Muette. Let's determine the overlapping part.\n",
    "\n",
    "GeoPandas and matplotlib and are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a106cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two polygons\n",
    "geopandas.GeoSeries([park_boulogne, muette]).plot(alpha=0.5, color=['green', 'blue'])\n",
    "plt.show()\n",
    " \n",
    "# Calculate the intersection of both polygons\n",
    "intersection = park_boulogne.intersection(muette)\n",
    " \n",
    "# Plot the intersection\n",
    "geopandas.GeoSeries([intersection]).plot()\n",
    "plt.show()\n",
    " \n",
    "# Print proportion of district area that occupied park\n",
    "print(intersection.area / muette.area)\n",
    "# 0.4352082235641065"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b9541",
   "metadata": {},
   "source": [
    "##### Intersecting a GeoDataFrame with a Polygon\n",
    "Combining the land use dataset and the districts dataset, we can now investigate what the land use is in a certain district.\n",
    "\n",
    "For that, we first need to determine the intersection of the land use dataset with a given district. Let's take again the Muette district as example case.\n",
    "\n",
    "The land use and districts datasets have already been imported as land_use and districts, and the Muette district has been extracted into the muette shapely polygon. Further, GeoPandas and matplotlib are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591dc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the land use datset and Notre-Dame district polygon\n",
    "print(land_use.head())\n",
    "print(type(muette))\n",
    " \n",
    "# Calculate the intersection of the land use polygons with Notre Dame\n",
    "land_use_muette = land_use.geometry.intersection(muette)\n",
    " \n",
    "# Plot the intersection\n",
    "land_use_muette.plot(edgecolor='black')\n",
    "plt.show()\n",
    " \n",
    "# Print the first five rows of the intersection\n",
    "print(land_use_muette.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a541bd",
   "metadata": {},
   "source": [
    "#### Overlay of two polygon layers\n",
    "Going back to the land use and districts datasets, we will now combine both datasets in an overlay operation. Create a new GeoDataFrame consisting of the intersection of the land use polygons with each of the districts, but make sure to bring the attribute data from both source layers.\n",
    "\n",
    "GeoPandas is already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa34036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five rows of both datasets\n",
    "print(land_use.head())\n",
    "print(districts.head())\n",
    " \n",
    "# Overlay both datasets based on the intersection\n",
    "combined = geopandas.overlay(land_use, districts, how='intersection')\n",
    " \n",
    "# Print the first five rows of the result\n",
    "print(combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad436d",
   "metadata": {},
   "source": [
    "##### Inspecting the overlay result\n",
    "Now that we created the overlay of the land use and districts datasets, we can more easily inspect the land use for the different districts. Let's get back to the example district of Muette, and inspect the land use of that district.\n",
    "\n",
    "GeoPandas and Matplotlib are already imported. The result of the overlay() function from the previous exercises is available as combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first rows of the overlay result\n",
    "print(combined.head())\n",
    " \n",
    "# Add the area as a column\n",
    "combined['area'] = combined.area\n",
    " \n",
    "# Take a subset for the Muette district\n",
    "land_use_muette = combined[combined.district_name=='Muette']\n",
    " \n",
    "# Visualize the land use of the Muette district\n",
    "land_use_muette.plot(column='class')\n",
    "plt.show()\n",
    " \n",
    "# Calculate the total area for each land use class\n",
    "print(land_use_muette.groupby('class')['area'].sum() / 1000**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d576ef9",
   "metadata": {},
   "source": [
    "##### Import and explore the data\n",
    "In this exercise, we will start with reading and exploring two new datasets:\n",
    "\n",
    "First, a dataset on artisanal mining sites in Eastern Congo (adapted from IPIS open data).\n",
    "Second, a dataset on the national parks in Congo (adapted from the World Resources Institute).\n",
    "For each of those datasets, the exercise consists of importing the necessary packages, reading the data with geopandas.read_file(), inspecting the first 5 rows and the Coordinate Reference System (CRS) of the data, and making a quick visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GeoPandas and Matplotlib\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Read the mining site data\n",
    "national_parks = geopandas.read_file(\"cod_conservation.shp\")\n",
    " \n",
    "# Print the first rows and the CRS information\n",
    "print(national_parks.head())\n",
    "print(national_parks.crs)\n",
    " \n",
    "# Make a quick visualisation\n",
    "national_parks.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add44cac",
   "metadata": {},
   "source": [
    "#### Convert to common CRS and save to a file\n",
    "As we have seen in the previous exercises, both datasets are using a different Coordinate Reference System (CRS). This is also illustrated by the first plot in this exercise (for which the code is already provided in the script): both datasets are about the same region, so they should normally overlap in their coordinates; but they don't.\n",
    "\n",
    "For further analyses in the rest of this chapter, we will convert both datasets to the same CRS, and save both to a new file. To ensure we can do distance-based calculations, we will convert them to a projected CRS: the local UTM zone 35, which is identified by EPSG:32735 (https://epsg.io/32735).\n",
    "\n",
    "The mining sites (mining_sites) and national parks (national_parks) datasets are already loaded, and GeoPandas and matplotlib are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974940ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the natural parks and mining site data\n",
    "ax = national_parks.plot()\n",
    "mining_sites.plot(ax=ax, color='red')\n",
    "plt.show()\n",
    " \n",
    "# Convert both datasets to UTM projection\n",
    "mining_sites_utm = mining_sites.to_crs(epsg=32735)\n",
    "national_parks_utm = national_parks.to_crs(epsg=32735)\n",
    " \n",
    "# Plot the converted data again\n",
    "ax = national_parks_utm.plot()\n",
    "mining_sites_utm.plot(ax=ax, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835df7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the mining site data\n",
    "mining_sites = geopandas.read_file(\"ipis_cod_mines.geojson\")\n",
    "national_parks = geopandas.read_file(\"cod_conservation.shp\")\n",
    " \n",
    "# Convert both datasets to UTM projection\n",
    "mining_sites_utm = mining_sites.to_crs(epsg=32735)\n",
    "national_parks_utm = national_parks.to_crs(epsg=32735)\n",
    " \n",
    "# Write converted data to a file\n",
    "mining_sites_utm.to_file('ipis_cod_mines_utm.gpkg', driver='GPKG')\n",
    "national_parks_utm.to_file(\"cod_conservation_utm.shp\", driver='ESRI Shapefile')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a52d39",
   "metadata": {},
   "source": [
    "#### Styling a multi-layered plot\n",
    "Now we have converted both datasets to the same Coordinate Reference System, let's make a nicer plot combining the two.\n",
    "\n",
    "The datasets in UTM coordinates as we saved them to files in the last exercise are read back in and made available as the mining_sites and national_parks variables. GeoPandas and matplotlib are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the parks and mining sites\n",
    "ax = national_parks.plot(color='green')\n",
    "mining_sites.plot(ax=ax, column = 'mineral', markersize=5, legend=True)\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbcb22d",
   "metadata": {},
   "source": [
    "#### Buffer around a point\n",
    "Consider the city of Goma, the capital of the North Kivu province of Congo, close to the border with Rwanda. Its coordinates are 1.66°S 29.22°E (the Point is already provided in UTM coordinates as the goma variable).\n",
    "\n",
    "How many mining sites are located within 50 km of Goma? And how much area of national park? Let's determine that using the buffer operation. Remember that distances should be expressed in the unit of the CRS (i.e. in meter in this case).\n",
    "\n",
    "Note: if you have a boolean Series (for example as result of a spatial relationship method), then you can calculate how many True values (ie. how many geometries passed the check) by taking the sum of those booleans because in that case the True and False values will be seen as ones and zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f7e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goma is a Point\n",
    "print(type(goma))\n",
    " \n",
    "# Create a buffer of 50km around Goma\n",
    "goma_buffer = goma.buffer(50000)\n",
    " \n",
    "# The buffer is a polygon\n",
    "print(type(goma_buffer))\n",
    " \n",
    "# Check how many sites are located within the buffer\n",
    "mask = mining_sites.within(goma_buffer)\n",
    "print(mask.sum())\n",
    " \n",
    "# Calculate the area of national park within the buffer\n",
    "print(national_parks.intersection(goma_buffer).area.sum() / (1000**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b93e3d",
   "metadata": {},
   "source": [
    "#### Mining sites within national parks\n",
    "For this exercise, let's start with one of the national parks, the Kahuzi-Biega National park (which was extracted from the national_parks dataset and is provided as the kahuzi variable).\n",
    "\n",
    "Which of the mining sites are located within this national park?\n",
    "\n",
    "And as a second step: can we determine all mining sites that are located within one of the national parks and in which park?\n",
    "\n",
    "The mining sites (mining_sites) and national parks (national_parks) datasets are already loaded, and GeoPandas is already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5141ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the single polygon for the Kahuzi-Biega National park\n",
    "kahuzi = national_parks[national_parks['Name'] == \"Kahuzi-Biega National park\"].geometry.squeeze()\n",
    " \n",
    "# Take a subset of the mining sites located within Kahuzi\n",
    "sites_kahuzi = mining_sites[mining_sites.within(kahuzi)]\n",
    "print(sites_kahuzi)\n",
    " \n",
    "# Determine in which national park a mining site is located\n",
    "sites_within_park = geopandas.sjoin(mining_sites, national_parks, op='within', how='inner')\n",
    "print(sites_within_park.head())\n",
    " \n",
    "# The number of mining sites in each national park\n",
    "print(sites_within_park['name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a66b0e",
   "metadata": {},
   "source": [
    "#### Finding the name of the closest National Park\n",
    "Let's start with a custom query for a single mining site. Here, we will determine the name of the national park that is the closest to the specific mining site.\n",
    "\n",
    "The datasets on the mining sites (mining_sites) and national parks (national_parks) are already loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the geometry of the first row\n",
    "single_mine = mining_sites.geometry[0]\n",
    " \n",
    "# Calculate the distance from each national park to this mine\n",
    "dist = national_parks.distance(single_mine)\n",
    " \n",
    "# The index of the minimal distance\n",
    "idx = dist.idxmin()\n",
    " \n",
    "# Access the name of the corresponding national park\n",
    "closest_park = national_parks.loc[idx, 'Name']\n",
    "print(closest_park)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1442f7",
   "metadata": {},
   "source": [
    "#### Applying a custom operation to each geometry\n",
    "Now we know how to get the closest national park for a single point, let's do this for all points. For this, we are first going to write a function, taking a single point as argument and returning the desired result. Then we can use this function to apply it to all points.\n",
    "\n",
    "The datasets on the mining sites (mining_sites) and national parks (national_parks) are already loaded. The single mining site from the previous exercises is already defined as single_mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that returns the closest national park\n",
    "def closest_national_park(geom, national_parks):\n",
    "    dist = national_parks.distance(geom)\n",
    "    idx = dist.idxmin()\n",
    "    closest_park = national_parks.loc[idx, 'Name']\n",
    "    return closest_park\n",
    " \n",
    "# Call the function on single_mine\n",
    "print(closest_national_park(single_mine, national_parks))\n",
    " \n",
    "# Apply the function to all mining sites\n",
    "mining_sites['closest_park'] = mining_sites.geometry.apply(closest_national_park, national_parks=national_parks)\n",
    "print(mining_sites.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65b837",
   "metadata": {},
   "source": [
    "#### Import and plot raster data\n",
    "In this exercise, we are going to use a raster dataset of the vegetation types map (available from http://www.wri.org). The raster values take a set of discrete values indicating the type of vegetation. Let's start with reading the data and plotting it together with the mining site data.\n",
    "\n",
    "The mining sites dataset (mining_sites) is already loaded, and GeoPandas and matplotlib are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b36c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rasterio package\n",
    "import rasterio\n",
    " \n",
    "# Open the raster dataset\n",
    "src = rasterio.open(\"central_africa_vegetation_map_foraf.tif\")\n",
    " \n",
    "# Import the plotting functionality of rasterio\n",
    "import rasterio.plot\n",
    " \n",
    "# Plot the raster layer with the mining sites\n",
    "ax = rasterio.plot.show(src)\n",
    "mining_sites.plot(ax=ax, color='red', markersize=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943a48e",
   "metadata": {},
   "source": [
    "#### Extract information from raster layer\n",
    "Let's now extract information from the raster layer, based on a vector file. This functionality is provided by the rasterstats package. Specifically for this exercise, we will determine the vegetation type at all mining sites, by getting the nearest raster pixel value at each point of the mining site dataset.\n",
    "\n",
    "A subset of the mining sites dataset (mining_sites) is already loaded, and GeoPandas and matplotlib are already imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rasterstats package\n",
    "import rasterstats\n",
    " \n",
    "# Extract the nearest value in the raster for all mining sites\n",
    "vegetation_raster = \"central_africa_vegetation_map_foraf.tif\"\n",
    "mining_sites['vegetation'] = rasterstats.point_query(mining_sites.geometry, vegetation_raster, interpolate='nearest')\n",
    "print(mining_sites.head())\n",
    " \n",
    "# Replace numeric vegation types codes with description\n",
    "mining_sites['vegetation'] = mining_sites['vegetation'].replace(vegetation_types)\n",
    " \n",
    "# Make a plot indicating the vegetation type\n",
    "mining_sites.plot(column='vegetation', legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410320fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37aff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52882ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88bf5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecc6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb305ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb050447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1846732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fb0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41118791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a83d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53344640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ed536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a9b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac993cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21277a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
